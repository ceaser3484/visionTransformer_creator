데이터셋은 위에 말했듯 옥스퍼드 iiit-pet로https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz 와  https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz에서 다운로드가 가능하고, 총37개의 클래스이며 강아지 25종, 고양이12종이 각 200장 정도씩 총 7300장 정도 있는 데이터셋으로 3680개씩 dataloder로 나누어서 진행했습니다. 훈련 코드 자체는 전에 배웠던 cnn 전이학습 코드 써서 한거였고, 지금 보여드리는 사진은 간단한 증류한번 적용해서 google/vit-base-patch16-224-in21k를 증류하고 있는 과정입니다. 지금 268에포크 + 255에포크를 진행하고 있습니다. 손실이 큰 이유가 구글 모델의 cls토큰과 저희 모델의 cls 토큰의 mse를 일정 비율로 더해서 커진겄으로 보통 검증 손실값과 비슷한 값이 나옵니다. 증류는 일단 간단하게 저희가 배웠던 autofeatureextractor로 모델에 맞는 이미지 전처리 하고 """inputs = feature_extractor(images=X_train, return_tensors="pt", do_rescale=False).to(device)""" 그 이후에 이미지를 모델에 집어넣은 후 """teacher_outputs = teacher(**inputs, output_hidden_states=True)""" 결과에서 마지막 cls토큰만 빼서 ""'teacher_cls = teacher_outputs.hidden_states[-1][:, 0]""" 그 토큰과 우리 모델의 마지막 cls토큰을  """feature_loss = F.mse_loss(student_cls, teacher_cls)""" mse로 비교한 값을 일정 비율로 원래 로스에 더한 """loss = (1 - lambda_kd) * st_loss + lambda_kd * feature_loss""" 형태입니다. lambda_kd는 비율을 어떻게 할지에 대한 값으로 0.7로 설정하고 훈련을 진행중입니다. 원래는 더 복잡한데, 복잡해서 일단 이해한 것만 간단히 구현해 본거라서 사실 증류성능이 썩 좋은거 같진 않습니다.